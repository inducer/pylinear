\chapter{The \class{Array} types}
\begin{quote}
   This chapter decribes the basic array types provided by PyLinear, and
   the elementary operations available on them.
\end{quote}

The present chapter describes the module \module{pylinear.array}. It is
assumed to be imported using
\begin{verbatim}
>>> from pylinear.array import *
\end{verbatim}
in the examples.

\section{Types and flavors}
\label{sec:types-and-flavors}
PyLinear provides four flavors of arrays with two different element
types each.  The possible \dfn{flavors}\index{flavor} are:
\begin{itemize}
  \item dense vector\indexii{Dense}{Vector},
  \item dense matrix\indexii{Dense}{Matrix},
  \item sparse build matrix\indexiii{Sparse}{Build}{Matrix}, and
  \item sparse execute matrix\indexiii{Sparse}{Execute}{Matrix}.
\end{itemize}
From this point onwards, we will use the term \class{Array}\index{array}
to mean any type of matrix or vector. The term \class{Matrix}\index{matrix}
will refer to any of the matrix types. The term \class{Vector}\index{vector}
shall refer to only the dense vector type. Note that these do not exist as
classes as such, but we will pretend that they do.

The supported element types are
\begin{itemize}
  \item double precision (i.e. 64-bit) real, and
  \item double precision (i.e. 2x64-bit) complex.
\end{itemize}

PyLinear only allows vectors and matrices (i.e.  objects with one and
two index dimensions, but no tensors or other higher-dimensional
objects). There is only one vector flavor, but there are three
different flavors of matrices with different performance and memory
characteristics. \emph{Dense} matrices store \var{m}-by-\var{n}
elements in a two-dimensional grid of \var{m} rows and \var{n}
columns. They are used for small matrices or those which have mostly
non-zero elements. Contrast this with the sparse types, which are
typically used for matrices consisting of mostly zero
elements. \emph{Sparse build} matrices store their elements a list of
\samp{(i, j, a[i,j])}, to which new elements are simply appended,
which is very fast. This list is typically unsorted, but may have to
be sorted by \var{i} and \var{j} for multiplication, element access or
element removal, which makes these operations pretty
slow. Consequently, this flavor is typically used for the assembly of
large sparse matrices. It is then converted to the \emph{sparse
execute} flavor for fast matrix multiplication. This flavor uses a
standard compressed column format for fast linear algebra operations.

Each of the flavors is represented by a symbolic constant:

\begin{tableii}{l|l}{constant}{Constant}{Corresponding Flavor}
  \lineii{Vector}
         {The dense vector flavor.}
  \lineii{DenseMatrix}
         {The dense matrix flavor.}
  \lineii{SparseBuildMatrix}
         {The sparse build matrix flavor.}
  \lineii{SparseExecuteMatrix}
         {The sparse execute matrix flavor.}
\end{tableii}

Likewise, each of the element types has its own symbolic constant.
These constants are usually called \indexii{type}{code}\index{typecode}\dfn{typecodes}.

\begin{tableii}{l|l}{constant}{Constant}{Corresponding Element Type}
  \lineii{Float64}
         {The 64-bit real element type.}
  \lineii{Complex64}
         {The 2x64-bit complex element type.}
  \lineii{Float}
         {The machine-native C++ \ctype{double} element type.
          An alias for \constant{Float64}.}
  \lineii{Complex}
         {The machine-native C++ \ctype{std::complex<double>} 
          element type. An alias for \constant{Complex64}.}
\end{tableii}

Despite some dissimilarity, PyLinear's matrix layer attempts to be
mostly compatible with Numerical Python.

% --------------------------------------------------------------------------
\section{Creating \class{Array}s}

The following functions in the module \module{pylinear.array} permit
the creation of new \class{Array}s:

\begin{funcdesc}{array}{sequence, typecode=None}
   There are many ways to create arrays. The most basic one is the use of the
   \function{array} function:
\begin{verbatim}
>>> a = array([1.2, 3.5, -1])
\end{verbatim}
   to make sure this worked, do:
\begin{verbatim}
>>> a
\end{verbatim}
   The \function{array} function takes several arguments --- the first
   one is a Python sequence object (such as a list or a tuple).  The
   optional argument \code{type} specifies the element type of the
   matrix. If omitted, as in the example above, Python tries to find
   the best data type which can represent all the
   elements. \function{array} always creates dense matrices or
   vectors, depending on the \dfn{dimensionality}\index{dimension} of
   the input data.  (The dimension of the data is 1 for a list, 2 for
   a list of lists, and so on.  1-dimensional data will be converted
   to vectors, 2-dimensional data to matrices.)
   
   Since the elements we gave our example were two floats and one integer, it
   chose \class{Float64} as the type of the resulting array. One can specify
   unequivocally the \code{type} of the elements---this is especially 
   useful when, for example, one wants an array contains complex numbers even
   though all of its input elements are reals:
\begin{verbatim}
>>> array([1,2,3]) # reals are enough for 1, 2 and 3
>>> array([1,2,3], typecode=Complex64) # not the default type
>>> array([1,2,3+0j]) # same effect
\end{verbatim}
    Note that in NumPy, \function{array} takes a few more arguments, such as
    \code{copy}, \code{savespace}, and \code{shape}. These are not supported.
\end{funcdesc}

\begin{funcdesc}{sparse}{mapping, shape=None, typecode=None, flavor=SparseBuildMatrix}
  This function creates a (not necessarily sparse) \class{Matrix} of
  the given \code{shape}, \code{typecode}, and \code{flavor} based on
  a sparse representation of its entries. At present, it cannot create
  \class{Vector}s. The sparse representation consists of a dictionary
  of dictionaries, whose keys are the row indices for the outer dictionary,
  and the column indices for the inner one.

  If the \code{shape} parameter is unspecified, the shape is specified by
  the largest row and column indices seen in examining the \code{mapping}.
  If the \code{typecode} is unspecified, \function{sparse} uses the same
  logic as \function{data} to determine it.
\begin{verbatim}
>>> sparse({0:{4:17, 3:1+2j},3:{2:15}})
>>> sparse({0:{4:17, 3:1+2j},3:{2:15}}, flavor=SparseExecuteMatrix)
\end{verbatim}
\end{funcdesc}

\begin{funcdesc}{asarray}{seq, typecode, flavor=None}
  This function converts scalars, lists and tuples to an
  \class{Array} type, if possible. It passes \class{Array}s through,
  making copies only to convert types.  In any other case a
  \class{TypeError} is raised.
\end{funcdesc}

\begin{funcdesc}{zeros}{shape, typecode, flavor=None}
  \function{zeros} creates an \class{Array} of the given \var{shape},
  \var{typecode} and \var{flavor} which is filled with zeros. See the
  \member{shape} attribute in Section \ref{sec:arrayproperties} for
  information on the \var{shape} parameter.
\begin{verbatim}
>>> zeros((2,5), Float)
\end{verbatim}
\end{funcdesc}

\begin{funcdesc}{ones}{shape, typecode, flavor=None}
  \function{ones} creates an \class{Array} of the given \var{shape},
  \var{typecode} and \var{flavor} which is filled with ones. See the
  \member{shape} attribute in Section \ref{sec:arrayproperties} for
  information on the \var{shape} parameter.
\begin{verbatim}
>>> ones((3,7), Float)
\end{verbatim}
\end{funcdesc}

\begin{funcdesc}{identity}{n, typecode, flavor=None}
  \function{identity} creates a \class{Matrix} of shape \code{(n,n)} and
  the given \var{typecode} and \var{flavor} which is filled with
  zeros and has ones on the diagonal, a type of matrix otherwise
  known as an identity matrix.
\begin{verbatim}
>>> identity(4, Complex)
\end{verbatim}
\end{funcdesc}

\subsection{Pickle support}
\class{Array}s also have efficient support for pickling. Pickling is a
convenient way to store complicated data structures in a platform-independent
byte stream. Unless you need human-readable output, pickling makes an
excellent way of saving PyLinear arrays to disk.

Unpickling a previously pickled \class{Array} is another way to create one:

\begin{verbatim}
>>> x = array([[1,2,3],[4,5,6]])
>>> import pickle
>>> string_rep = pickle.dumps(x)
>>> isinstance(string_rep, str)
>>> y = pickle.loads(string_rep)
>>> y
\end{verbatim}

Pickling also works on arbitrarily larger data structures of which
\class{Array}s are only a part.

% --------------------------------------------------------------------------
\section{Accessing \class{Array} properties}

\label{sec:arrayproperties}
An \class{Array} has the following meta-data attributes:

\begin{memberdesc}[Array]{shape}
  Reading the \member{shape} attribute gets the shape tuple, that is,
  a tuple of length equal to the array's dimension specifying the
  dimensions of the matrix.  For a vector, this is a singleton
  containing an integer, for a matrix, this is a pair containing the
  number of rows and columns, in this order.  

  Assigning a value to the \member{shape} attribute will destructively
  resize the array.

\begin{verbatim}
>>> x = array([[1,2,3],[4,5,6]])
>>> x.shape
>>> x.T.shape
>>> x.shape = (4,2)
>>> x # typically random garbage
\end{verbatim}
\end{memberdesc}

\begin{memberdesc}[Array]{flavor}
  Reading the \member{flavor} attribute gets the flavor of the given
  matrix. Assigning a value to the \member{flavor} attribute is not supported.
\end{memberdesc}

An \class{Array} has the following meta-data-returning methods:

\begin{methoddesc}[Array]{typecode}{}
  Returns the typecode of the matrix.
\begin{verbatim}
>>> x = array([[1,2,3],[4,5,6]])
>>> x.typecode()
>>> x = array([[1+3j,2-4j,3],[4,5+1j,6]])
>>> x.typecode()
\end{verbatim}
\end{methoddesc}

% --------------------------------------------------------------------------
\section{Accessing and modifying \class{Array} data}

An \class{Array} has the following data attributes:

\begin{memberdesc}[Array]{real}
  Reading this attribute obtains a copy of the real part of the matrix.
  For real matrices, the matrix is simply copied.

  In NumPy, this method does not return a copy, but a view.
\begin{verbatim}
>>> x = array([[1+3j,2-4j,3],[4,5+1j,6]])
>>> x
>>> x.real
\end{verbatim}
\end{memberdesc}

\begin{memberdesc}[Array]{imaginary}
  Reading this attribute obtains a copy of the imaginary part of the matrix.
  For real matrices, a zero matrix of the same size is returned.

  In NumPy, this method does not return a copy, but a view.
\begin{verbatim}
>>> x = array([[1+3j,2-4j,3],[4,5+1j,6]])
>>> x
>>> x.imaginary
\end{verbatim}
\end{memberdesc}

In addition to the \class{Array} data attributes, \class{Matrix} types
offer the following:

\begin{memberdesc}[Matrix]{T}
  Returns a real-transpose copy of the matrix.

  Does not exist in NumPy.
\begin{verbatim}
>>> x = array([[1,2,3],[4,5,6]])
>>> x
>>> x.T
\end{verbatim}
\end{memberdesc}

\begin{memberdesc}[Matrix]{H}
  Returns a conjugate-transpose copy of the matrix.
  Identical to \member{T} for real matrices.

  Does not exist in NumPy.
\begin{verbatim}
>>> x = array([[1+3j,2-4j,3],[4,5+1j,6]])
>>> x
>>> x.H
\end{verbatim}
\end{memberdesc}

Naturally, PyLinear will also support indexing for reading and writing
on \class{Array}s. Typically, matrices are indexed by 2-tuples,
whereas vectors are indexed by single values. Indexing a matrix with a
single value will return the entire row. Regular Python slice syntax
is supported, so that you can write \code{a[3:17]}, \code{a[1:3,5:9]},
or even \code{a[::-1]}. Unlike Python lists, \class{Array}s may not be
resized using slice assignments. Like in the rest of Python, yet
unlike NumPy, slices return copies, not views of the corresponding
data.

The following methods are available on PyLinear's \class{Array} types:

\begin{methoddesc}{sum}{}
  The \method{sum} method returns the sum of all non-zero array elements. (Saying
  ``non-zero'' sounds stupid, but it actually means that for sparse arrays,
  only non-zero elements are considered, and thus represents a guarantee
  with respect to asymptotic complexity of the operation.)
  Returns the sum of all elements in the array.
\begin{verbatim}
>>> x = array([[1,2,3],[4,5,6]])
>>> x.sum()
>>> v = array([1,2,3])
>>> v.sum()
\end{verbatim}
\end{methoddesc}
%\begin{methoddesc}{abs_square_sum}{} INTENTIONALLY LEFT OUT
%  Returns the sum of the squared absolute values of all elements in
%  the array.
%\end{methoddesc}
\begin{methoddesc}{__iter__}{}
  For \class{Matrix} types, this method returns an iterator whose
  consecutive values are the rows of the matrix. Note that this method
  always returns a \emph{dense} \class{Vector}, so it can be slow
  to use for sparse matrices.

  For \class{Vector}s, this method returns an iterator whose
  consecutive values are the entries of the vector.

  This method is implicitly called in \code{for} loops:
\begin{verbatim}
>>> x = array([[1,2,3],[4,5,6]])
>>> for row in x:
...   print row
...
>>> x = array([1,2,3])
>>> for entry in x:
...   print entry
...
\end{verbatim}
\end{methoddesc}
\begin{methoddesc}{indices}{}
  This method works like the \method{keys}() method on a
  dictionary: It returns an iterator whose values are all indices
  of the \class{Array} for which the corresponding value is
  potentially non-zero. (That is, for dense matrices, it returns
  each element's index, while for sparse matrices, only non-zero
  elements are enumerated.)
\begin{verbatim}
>>> x = sparse({0:{4:17, 3:1+2j},3:{2:15}})
>>> for index in x.indices():
...   print index
\end{verbatim}
\end{methoddesc}
\begin{methoddesc}{add_scattered}{row_indices, column_indices, little_matrix}
  Modifies the called matrix in-place by adding a the entries of a
  \var{little_matrix} to the already present entries, where the
  affected rows and columns are given by \var{row_indices},
  \var{column_indices}.
\begin{verbatim}
>>> a = zeros((10,10), Float, SparseBuildMatrix)
>>> b = array([[1,2],[3,4]])
>>> a.add_scattered([4,8], [1,3], b)
>>> a
\end{verbatim}
  This operation is common in finite element codes.
\end{methoddesc}
\begin{methoddesc}{copy}{}
  Returns an identical copy of the matrix.
\begin{verbatim}
>>> a = array([1,2,3])
>>> b = a.copy()
>>> b[0] = 15
>>> a
>>> b
\end{verbatim}
\end{methoddesc}
\begin{methoddesc}{solve_upper}{vector}
  If the matrix is an non-singular upper triangular matrix, then a vector
  \code{result} is returned that satisfies \code{matrix*result=vector}, i.e.
  this routine solves the linear system given by the matrix.

  If the matrix is not regular upper triangular, then the result of this routine
  is still a vector, but of undefined meaning.
\begin{verbatim}
>>> a = array([[1,2],[0,3]])
>>> b = array([17,12])
>>> v = a.solve_upper(b)
>>> v
>>> a*v
\end{verbatim}
\end{methoddesc}
\begin{methoddesc}{solve_lower}{vector}
  If the matrix is an non-singular lower triangular matrix, then a vector
  \code{result} is returned that satisfies \code{matrix*result=vector}, i.e.
  this routine solves the linear system given by the matrix.

  If the matrix is not regular upper triangular, then the result of this routine
  is still a vector, but of undefined meaning.
  
\begin{verbatim}
>>> a = array([[1,0],[3,4]])
>>> b = array([17,12])
>>> v = a.solve_lower(b)
>>> v
>>> a*v
\end{verbatim}
\end{methoddesc}

The following methods tie into the particulars of the sparse matrices'
memory layouts.

\begin{methoddesc}[SparseBuildMatrix]{sort}{}
  The list of $(i,j,a_{i,j})$ stored by a \class{SparseBuildMatrix}
  can become unsorted, depending on the order of insertions into the
  matrix.  This is rectified by the \method{sort} method. During
  normal usage, you don't have to worry about sorting your matrices,
  since this action is triggered automatically whenever it is
  necessary.
\end{methoddesc}
\begin{methoddesc}{set_element}{i, j, entry}
  Sets the entry in the \var{i}th row and \var{j}th column to the
  value \var{entry}.

  Why would you want this if you could easily say \code{A[i,j] =
  entry}? This method is guaranteed to be an O(1) operation if it is
  available, whereas the alternative notation will always work, but
  may be exceedingly slow. (Consider the case of a
  \class{SparseExecuteMatrix}, which might have to perform an $O(n^2)$
  move to accomodate a new element.)

  Available on all but \class{SparseExecuteMatrix} objects.
\end{methoddesc}
\begin{methoddesc}[Matrix]{set_element_past_end}{i, j, entry}
  Sets the entry in the \var{i}th row and \var{j}th column to the
  value \var{entry}. If used, the user guarantees that for all
  $k>i$, $A_{k,l}=0$ for all $l$ and that $A_{i,l}=0$ for $l>=j$.

  Why would you want this if you could easily say \code{A[i,j] =
  entry}? This method is guaranteed to be an O(1) operation if 
  it is available, whereas the alternative notation will always
  work, but may be exceedingly slow. (Consider the case of a
  \class{SparseBuildMatrix}, which might have to be resorted.)
\end{methoddesc}
\begin{methoddesc}[Matrix]{add_element}{i, j, number}
  Adds \var{number} to the entry in the \var{i}th row and \var{j}th
  column.

  Why would you want this if you could easily say \code{A[i,j] +=
  entry}? This method is guaranteed to be an O(1) operation if it is
  available, whereas the alternative notation will always work, but
  may be exceedingly slow. (Consider the case of a
  \class{SparseExecuteMatrix}, which might have to perform an $O(n^2)$
  move to accomodate a new element.)

  Available on all but \class{SparseExecuteMatrix} objects.
\end{methoddesc}
\begin{methoddesc}[SparseExecuteMatrix]{complete_index1_data}{}
  This is a rather internal method, but it is explained here
  nonetheless.

  The \class{SparseExecuteMatrix} class uses a list to indicate the
  column starts in a linear field of numbers. This list of column
  starts, in its original state, is usually incomplete, i.e. does not
  cover all rows, which allows $O(1)$ insertion at the end of the
  number field. This method makes sure that the column start list is
  complete. This is required by certain third-party sparse matrix
  libraries that directly read the structure of your sparse
  matrices. Within PyLinear, UMFPACK is one such example. Its wrappers
  call this method automatically, however, so that you don't have to
  worry about this here. But if you are binding to other sparse matrix
  libraries, this call might come in useful.
\end{methoddesc}

PyLinear also supports a number of data access functions.

Some of them resemble NumPy's functionality and ease the porting between
different matrix libraries:

\begin{funcdesc}{diagonal}{matrix, offset=0}
  Returns the diagonal of \var{matrix} as a vector, or the \var{offset}th
  super- (for \code{offset>0}) or sub-diagonal (for \code{offset<0}).
\begin{verbatim}
>>> a = array([[1,2,3],[4,5,6]])
>>> a
>>> diagonal(a)
>>> diagonal(a,1)
\end{verbatim}
\end{funcdesc}
\begin{funcdesc}{take}{matrix, indices, axis=0}
  Assembles an \class{Array} from the entries of the \class{Array}
  listed in \var{indices}, which must be simple numbers. \var{axis}
  specifies the axis along which the indices are taken.
\end{funcdesc}
\begin{funcdesc}{matrixmultiply}{op1, op2}
  Equivalent to \code{op1*op2}.
\end{funcdesc}
\begin{funcdesc}{innerproduct}{op1, op2}
  Equivalent to \code{op1*op2}.
\end{funcdesc}
\begin{funcdesc}{outerproduct}{op1, op2}
  Equivalent to \code{op1 <<outer>> op2}.
\end{funcdesc}
\begin{funcdesc}{transpose}{op1}
  Equivalent to \code{op1.T}.
\end{funcdesc}
\begin{funcdesc}{hermite}{op1}
  Equivalent to \code{op1.H}.
\end{funcdesc}
\begin{funcdesc}{trace}{matrix, offset=0}
  Returns the sum of the \var{offset}th diagonal. See \function{diagonal}
  for details of the meaning of \var{offset}.
\begin{verbatim}
>>> a = array([[1,2,3],[4,5,6]])
>>> a
>>> trace(a)
>>> trace(a,1)
\end{verbatim}
\end{funcdesc}
% --------------------------------------------------------------------------
\section{Elementary computations with matrices}
\class{Array}s support the operators \code{+} (binary), \code{+=},
\code{-} (binary), \code{-=}, as well as \code{+} (unary) and \code{-}
(unary) with their elementwise meanings as you would expect them.
Multiplication and division are also supplied, but have slightly more
intricate meanings, as discussed in Section
\ref{subsec:arraymultiplication}.

\subsection{Type promotion}
\label{subsec:arraypromotion}

If binary operators or elementwise functions (see Section
\ref{subsec:elementwise-funcs}) are applied to arrays of non-matching flavor or
typecode, the operands are promoted to a common type. (For the case of
non-matching dimension, see Section \ref{subsec:arraybroadcast} for
broadcasting rules.)

If the only mismatch is in typecode, one argument array
is cast upward in the type hierarchy (e.g. from integer to real,
from real to complex) in order to match the other.

If there is also a mismatch in flavor, the matrix with the typecode
which is higher up in the type hierarchy determines the flavor of the
result.

\subsection{Broadcasting}
\label{subsec:arraybroadcast}

The binary elementwise operators as well as all the binary elementwise
functions (see Section \ref{subsec:elementwise-funcs}) accept argument pairs
where one argument has lesser dimension than the other. In this case, the
missing dimensions are \index{broadcasting}\dfn{broadcast} across the remainder
of the matrix. If the lesser-dimension argument is a scalar, this is easy to
explain: It is treated like an array of the right size filled with that scalar.
If it is a vector, it is treated like a matrix filled with rows consisting of
the given vector.

All of this can only work if the corresponding \class{Array} sizes 
match.

\subsection{Elementwise Functions}
\label{subsec:elementwise-funcs}

PyLinear sports a few so-called \dfn{Elementwise Functions},
\indexii{Universal}{Function}\indexii{Elementwise}{Function} some of which are
\emph{unary}, while others are \emph{binary}. (In NumPy, this kind of function
is called a ufunc, or ``Universal Function''.) Elementwise functions generally
apply a certain functionality to each element in an array. For example, the
\function{sin} elementwise function computes the sine of each of the given
array's entries, and returns the processed matrix, which will be of the same
size, flavor, and typecode. Binary elementwise functions receive two
\class{Array}s of equal size as arguments, apply a binary function (such as,
for example, addition or multiplication) to each pair of entries of the two
\class{Array}s, pairing the entries at the same location in each \class{Array},
and return an \class{Array} with the results. Binary elementwise functions obey
type promotion laws as laid out in section \ref{subsec:arraypromotion}.

The following unary elementwise functions exist:

\begin{funcdesc}{conjugate}{array}
  Returns the complex-conjugate of the given \class{Array}. Simply
  copies real matrices.
\end{funcdesc}
\begin{funcdesc}{cos}{array}
  Returns the elementwise cosine of the given \class{Array}.
\end{funcdesc}
\begin{funcdesc}{cosh}{array}
  Returns the elementwise hyperbolic cosine of the given
  \class{Array}.
\end{funcdesc}
\begin{funcdesc}{exp}{array}
  Returns the elementwise natural exponential of the given
  \class{Array}. 

  \emph{WARNING:} This is not matrix exponentiation.
\end{funcdesc}
\begin{funcdesc}{log}{array}
  Returns the elementwise natural logarithm of the given
  \class{Array}.
\end{funcdesc}
\begin{funcdesc}{log10}{array}
  Returns the elementwise base-10 logarithm of the given
  \class{Array}.
\end{funcdesc}
\begin{funcdesc}{sin}{array}
  Returns the elementwise sine of the given \class{Array}.
\end{funcdesc}
\begin{funcdesc}{sinh}{array}
  Returns the elementwise hyperbolic sine of the given \class{Array}.
\end{funcdesc}
\begin{funcdesc}{sqrt}{array}
  Returns the elementwise square root of the given \class{Array}.
\end{funcdesc}
\begin{funcdesc}{tan}{array}
  Returns the elementwise tangent of the given \class{Array}.
\end{funcdesc}
\begin{funcdesc}{tanh}{array}
  Returns the elementwise hyperbolic tangent of the given \class{Array}.
\end{funcdesc}
\begin{funcdesc}{floor}{array}
  Returns the elementwise floor of the given \class{Array}.
\end{funcdesc}
\begin{funcdesc}{ceil}{array}
  Returns the elementwise ceiling of the given \class{Array}.
\end{funcdesc}
\begin{funcdesc}{argument}{array}
  Returns the elementwise complex argument of the given \class{Array}.
  Resulting matrix consists of values of zero and $\pi$ for real matrices.
\end{funcdesc}
\begin{funcdesc}{absolute}{array}
  Returns the elementwise absolute value of the given \class{Array}.
\end{funcdesc}

The following binary elementwise functions exist:

\begin{funcdesc}{add}{op1, op2}
  Returns the elementwise sum of the given \class{Array}s. Obeys
  broadcasting (see Section \ref{subsec:arraybroadcast}) and type
  promotion (see Section \ref{subsec:arraypromotion}) laws.

  Equivalent to the \code{+} operator.
\end{funcdesc}
\begin{funcdesc}{subtract}{op1, op2}
  Returns the elementwise difference of the given \class{Array}s. Obeys
  broadcasting (see Section \ref{subsec:arraybroadcast}) and type
  promotion (see Section \ref{subsec:arraypromotion}) laws.

  Equivalent to the \code{-} operator.
\end{funcdesc}
\begin{funcdesc}{multiply}{op1, op2}
  Returns the elementwise product of the given \class{Array}s. Obeys
  broadcasting (see Section \ref{subsec:arraybroadcast}) and type
  promotion (see Section \ref{subsec:arraypromotion}) laws.

  \emph{NOT} equivalent to the \code{*} operator, except in the scalar
  case.
\end{funcdesc}
\begin{funcdesc}{divide}{op1, op2}
  Returns the elementwise quotient of the given \class{Array}s. Obeys
  broadcasting (see Section \ref{subsec:arraybroadcast}) and type
  promotion (see Section \ref{subsec:arraypromotion}) laws.

  \emph{NOT} equivalent to the \code{/} operator, except in the scalar
  case.
\end{funcdesc}
\begin{funcdesc}{power}{op1, op2}
  Returns the elementwise power \code{op1[i]**op2[i]} of the given
  \class{Array}s. Obeys broadcasting (see Section
  \ref{subsec:arraybroadcast}) and type promotion (see Section
  \ref{subsec:arraypromotion}) laws.

  \emph{NOT} equivalent to the \code{**} operator, except in the scalar
  case.
\end{funcdesc}
\begin{funcdesc}{maximum}{op1, op2}
  Returns the elementwise maximum of the given
  \class{Array}s. Obeys broadcasting (see Section
  \ref{subsec:arraybroadcast}) and type promotion (see Section
  \ref{subsec:arraypromotion}) laws.

  For complex matrices, the maximum is found based on the real part.
\end{funcdesc}
\begin{funcdesc}{minimum}{op1, op2}
  Returns the elementwise minimum of the given
  \class{Array}s. Obeys broadcasting (see Section
  \ref{subsec:arraybroadcast}) and type promotion (see Section
  \ref{subsec:arraypromotion}) laws.

  For complex matrices, the minimum is found based on the real part.
\end{funcdesc}

Additional elementwise function methods, such as \member{reduce}, as they are
found in NumPy, are not (yet) supported in PyLinear.

\subsection{Multiplication semantics}
\label{subsec:arraymultiplication}

This section explains the value of the expression\code{a*b}, where at
least one of \code{a} and \code{b} is an \class{Array}.

If the other operand is a scalar (it doesn't matter which), the
result will be the elementwise product of the array with that scalar.
\begin{verbatim}
>>> a = array([[1,2,3],[4,5,6]])
>>> a*2
>>> 2j*a
\end{verbatim}

If both operands are \class{Vector}s, \code{a*b} computes the inner
product of both vectors. Note that in the complex case no complex
conjugates are taken. If you require them, use the expression
\code{a*b.H}. \emph{WARNING:} This notation is convenient, but
slightly dangerous, mathematically. The inner product, if simply
written as a ``dot product'', is \emph{not} associative, meaning that
for vectors $a$, $b$ and $c$, typically $(a\cdot b)\cdot
c\not=a\cdot(b\cdot c)$.  PyLinear has no way of rejecting
unparenthesized expressions such as \code{a*b*c}, but their meaning is
uncertain since the order of evaluation is not explicitly specified.

\begin{verbatim}
>>> a = array([1,2,3])
>>> b = array([4,5,6])
>>> c = array([7,8,9])
>>> (a*b)*c
>>> a*(b*c)
>>> a*b*c # RANDOM RESULT!
\end{verbatim}

If \code{a} is a \class{Vector} and \code{b} is a \class{Matrix},
\code{a*b} will result in $b^Ta$, using the conventional matrix-vector
product.

If \code{a} is a \class{Matrix} and \code{b} is a \class{Vector},
\code{a*b} will result in $a b$, using the conventional matrix-vector
product.

\begin{verbatim}
>>> a = array([[1,2,3],[4,5,6],[7,8,9]])
>>> b = array([1,3,5])
>>> a*b
>>> b*a
>>> a.T*b # less efficient!
\end{verbatim}

If both \code{a} and \code{b} are \class{Matrix} types,
\code{a*b} will result in $a b$, using the conventional matrix-matrix
product.
\begin{verbatim}
>>> a = array([[1,2,3],[4,5,6]])
>>> b = array([[1,2,1,2],[3,4,3,4],[5,6,5,6]])
>>> a*b
\end{verbatim}

All these explanations also apply to the inplace multiplication
operator \code{*=}.

All multiplication operators obey type promotion rules as laid out
in Section \ref{subsec:arraypromotion}.

\subsection{Other \class{Array} operators}

The following expressions are also valid:
\begin{itemize} 
\item \code{matrix**n}

  Computes the \var{n}th power of \var{matrix}. \var{n} must be
  integer, but may be negative. Only for dense matrices.

\begin{verbatim}
>>> a = array([[1,2,3],[3,2,1],[1,3,2]])
>>> a
>>> a**2
>>> a**3
>>> a**3 * (1/a)
\end{verbatim}
\item \code{scalar/matrix}

  Computes the \var{scalar} multiple of the inverse of
  \var{matrix}. Only for dense matrices.

  Do not use code like \code{1/a*b} to solve the linear system
  $Ax=b$; besides being slow, this tends to yield imprecise
  results. Instead, use the \code{<<solve>>} pseudo-operator.

  Use of this operator will fail unless the module
  \module{pylinear.operation} is available.

\begin{verbatim}
>>> a = array([[1,2,3],[3,2,1],[1,3,2]])
>>> a
>>> 1/a
>>> 1/a * a
\end{verbatim}

  Observe that the results are likely useless if the matrix
  is singular:

\begin{verbatim}
>>> a = array([[1,2,3],[4,5,6],[7,8,9]])
>>> a
>>> 1/a
>>> 1/a * a
>>> from pylinear.computation import determinant
>>> determinant(a)
\end{verbatim}

\item \code{matrix <<solve>> vector}

  Returns the solution of the linear system of equations \code{matrix*x=vector}.
  Available for dense and sparse execute matrix types of \var{matrix}.

  Use of this operator will fail unless the module
  \module{pylinear.computation} is available.

  Since this is not built using actual Python syntax, but rather cheaply
  composed of a special-purpose \code{solve} object with left and right
  shift operators, some care needs to be exercised regarding operator
  precedence. When in doubt, just use parentheses.

\begin{verbatim}
>>> a = array([[1,2,3],[3,2,1],[1,3,2]])
>>> b = array([9,1,1])
>>> v = a <<solve>> b
>>> v
>>> a * v
\end{verbatim}

  Note that you need to qualify \code{<<solve>>} with the module name if you
  do not import \module{pylinear.array} using \samp{from ... import *}:

\begin{verbatim}
>>> import pylinear.array as num
>>> a = num.array([[1,2,3],[3,2,1],[1,3,2]])
>>> b = num.array([9,1,1])
>>> v = a <<num.solve>> b
>>> v
>>> a * v
\end{verbatim}

  Observe that the results are likely useless if the matrix
  is singular:

\begin{verbatim}
>>> a = array([[1,2,3],[4,5,6],[7,8,9]])
>>> b = array([9,1,1])
>>> v = a <<solve>> b
>>> v
>>> a * v
>>> from pylinear.computation import determinant
>>> determinant(a)
\end{verbatim}

\item \code{vector1 <<outer>> vector2}
  
  Computes the outer product of \code{vector1} and \code{vector2},
  whose result is the matrix $v_1 \cdot v_2^T$.

\begin{verbatim}
>>> v = array([1,2,3])
>>> w = array([3,2,1])
>>> v <<outer>> w
>>> w <<outer>> v
\end{verbatim}

  Please see the section on \code{<<solve>>} above for important
  considerations on operator precedence and module qualification
  that also apply here.

\item \code{vector1 <<cross>> vector2}
  
  Computes the cross product of \code{vector1} and \code{vector2}.
  Both \code{vector1} and \code{vector2} must be of dimension 2 or 3.
  For dimension 2, the $z$ component of the corresponding 3-dimensional
  cross product is returned as a scalar.

\begin{verbatim}
>>> v = array([1,2,3])
>>> w = array([3,2,1])
>>> v <<cross>> w
>>> w <<cross>> v
>>> (v <<cross>> w) * v
\end{verbatim}

  Please see the section on \code{<<solve>>} above for important
  considerations on operator precedence and module qualification
  that also apply here.

\end{itemize}
